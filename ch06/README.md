# Chapter 6 : Model Development and Offline Evaluation

1. [designing machine learning systems code](https://github.com/chiphuyen/dmls-book)

2. [Plotting Learning Curves and Checking Models’ Scalability](https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html)

3. [On the importance of the i.i.d. assumption in statistical learning](https://stats.stackexchange.com/questions/213464/on-the-importance-of-the-i-i-d-assumption-in-statistical-learning)

4. [The Most Comprehensive List of Kaggle Solutions and Ideas](https://farid.one/kaggle-solutions/)

5. [1st PLACE - WINNER SOLUTION - Gilberto Titericz & Stanislav Semenov](https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14335)

6. [SQuAD2.0 - The Stanford Question Answering Dataset](https://rajpurkar.github.io/SQuAD-explorer/)

7. [A Review on Ensembles for the Class Imbalance Problem: Bagging-, Boosting-, and Hybrid-Based Approaches](https://sci2s.ugr.es/keel/pdf/algorithm/articulo/2011-IEEE%20TSMC%20partC-%20GalarFdezBarrenecheaBustinceHerrera.pdf)

8. [Solving class imbalance problem using bagging, boosting techniques, with and without using noise filtering method](https://content.iospress.com/articles/international-journal-of-hybrid-intelligent-systems/his190261)

9. [Bagging Predictors](https://link.springer.com/article/10.1023/A:1018054314350)

10. [Machine Learning Challenge Winning Solutions](https://github.com/dmlc/xgboost/tree/master/demo#machine-learning-challenge-winning-solutions)

11. [Higgs Boson Discovery with Boosted Trees](http://proceedings.mlr.press/v42/chen14.html)

12. [LightGBM github](https://github.com/microsoft/LightGBM)

13. [Kaggle-Ensemble-Guide](https://github.com/MLWave/Kaggle-Ensemble-Guide)

14. [Deep Learning Determinism youtube](https://www.youtube.com/watch?v=TB07_mUMt0U)

15. [A Recipe for Training Neural Networks](http://karpathy.github.io/2019/04/25/recipe/)

16. [External memory algorithm](https://en.wikipedia.org/wiki/External_memory_algorithm)

17. [Saving memory using gradient-checkpointing](https://github.com/cybertronai/gradient-checkpointing)

18. [Distributed Deep Learning Using Synchronous Stochastic Gradient Descent](https://arxiv.org/abs/1602.06709)

19. [Revisiting Distributed Synchronous SGD](https://arxiv.org/abs/1604.00981)

20. [Improving MapReduce Performance in Heterogeneous Environments](https://static.usenix.org/event/osdi08/tech/full_papers/zaharia/zaharia.pdf)

21. [Addressing the straggler problem for iterative convergent parallel ML](http://davidwd.org/papers/aaron_straggler16.pdf)

22. [Large Scale Distributed Deep Networks](https://proceedings.neurips.cc/paper/2012/hash/6aca97005c68f1206823815f66102863-Abstract.html)

23. [Distributed TensorFlow](https://www.oreilly.com/content/distributed-tensorflow/)

24. [HOGWILD!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent](https://proceedings.neurips.cc/paper/2011/file/218a0aefd1d1a4be65601cc6ddc1520e-Paper.pdf)

25. [An Empirical Model of Large-Batch Training](https://arxiv.org/abs/1812.06162)

26. [Measuring the Effects of Data Parallelism on Neural Network Training](https://arxiv.org/abs/1811.03600)

27. [CS246: Mining Massive Data Sets](https://web.stanford.edu/class/cs246/)

28. [NVIDIA/Megatron-LM](https://github.com/NVIDIA/Megatron-LM)

29. [GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism](https://arxiv.org/pdf/1811.06965.pdf)

30. [ON THE STATE OF THE ART OF EVALUATION IN NEURAL LANGUAGE MODELS](https://arxiv.org/pdf/1707.05589.pdf)

31. [[D] How do people come up with all these crazy deep learning architectures?](https://www.reddit.com/r/MachineLearning/comments/6hso7g/comment/dj0tz1c/)

32. [[D] Debate about science at organizations like Google Brain/FAIR/DeepMind](https://www.reddit.com/r/MachineLearning/duplicates/8yvlzy/d_debate_about_science_at_organizations_like/)

33. [Grad student descent](https://sciencedryad.wordpress.com/2014/01/25/grad-student-descent/)

34. [Grad Student Descent: the preferred](https://twitter.com/guyzys/status/592847074170896384?lang=en)

35. [Ray Tune: Hyperparameter Tuning](https://docs.ray.io/en/latest/tune/index.html)

36. [NVIDIA/Milano](https://github.com/NVIDIA/Milano)

37. [Hyperparameter Optimization](https://www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf)

38. [Neural Architecture Search with Reinforcement Learning](https://arxiv.org/abs/1611.01578)

39. [Regularized Evolution for Image Classifier Architecture Search](https://arxiv.org/abs/1802.01548)

40. [DARTS: DIFFERENTIABLE ARCHITECTURE SEARCH](https://arxiv.org/pdf/1806.09055.pdf)

41. [Tasks, stability, architecture, and compute: Training more effective learned optimizers, and using them to train themselves](https://arxiv.org/abs/2009.11243)

42. [What Mark Zuckerberg’s News Feed looked like in 2006.](https://newsfeed.org/what-mark-zuckerbergs-news-feed-looked-like-in-2006/)

43. [The Evolution of Facebook News Feed](https://mashable.com/archive/facebook-news-feed-evolution)

44. [Rules of Machine Learning: Best Practices for ML Engineering](https://developers.google.com/machine-learning/guides/rules-of-ml?hl=en)

45. [Disparity in home lending costs minorities millions, researchers find](https://www.cbsnews.com/news/mortgage-discrimination-black-and-latino-paying-millions-more-in-interest-study-shows/)

46. [Calibrated recommendations](https://openreview.net/forum?id=-mUx28nmXvD)

47. [Platt scaling](https://en.wikipedia.org/wiki/Platt_scaling)

48. [Temperature Scaling](https://github.com/gpleiss/temperature_scaling)

49. [Why model calibration matters and how to achieve it](https://www.unofficialgoogledatascience.com/2021/04/why-model-calibration-matters-and-how.html)

50. [scikit learn - Probability calibration](https://scikit-learn.org/stable/modules/calibration.html#calibration)

51. [Google Photos Tags Two African-Americans As Gorillas Through Facial Recognition Software](https://www.forbes.com/sites/mzhang/2015/07/01/google-photos-tags-two-african-americans-as-gorillas-through-facial-recognition-software/?sh=5c2f0d23713d)

52. [Simpson's paradox](https://en.wikipedia.org/wiki/Simpson's_paradox)

53. [Comparison of treatment of renal calculi by open surgery, percutaneous nephrolithotomy, and extracorporeal shockwave lithotripsy.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1339981/)

54. [Sex Bias in Graduate Admissions: Data from Berkeley](https://homepage.stat.uiowa.edu/~mbognar/1030/Bickel-Berkeley.pdf)

55. [UX Design Across Different Cultures — Part 1](https://blog.prototypr.io/ux-design-across-different-cultures-part-1-1caa12a504c0)

56. [Slice Finder: Automated Data Slicing for Model Validation](https://ieeexplore.ieee.org/abstract/document/8731353)

57. [Subgroup Discovery Algorithms: A Survey and Empirical Evaluation](https://jcst.ict.ac.cn/EN/10.1007/s11390-016-1647-1)
